# æœ¬åœ°è¿è¡ŒLLM-EditCLIP Correlationæµ‹è¯•æŒ‡å—

## å¿«é€Ÿå¼€å§‹ï¼ˆ10åˆ†é’Ÿï¼‰

### æ­¥éª¤1: å…‹éš†ä»“åº“

```bash
# å…‹éš†æ‚¨çš„EditCLIPä»“åº“
git clone https://github.com/un1asting/EditCLIP.git
cd EditCLIP

# åˆ‡æ¢åˆ°correlationæµ‹è¯•åˆ†æ”¯
git checkout claude/test-llm-editclip-correlation-011CUrUh32wYnBtinfWY3zPk
```

### æ­¥éª¤2: å®‰è£…ä¾èµ–

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# å®‰è£…ä¾èµ–åŒ…
pip install torch torchvision transformers scipy tqdm pillow

# æˆ–è€…ä½¿ç”¨å›½å†…é•œåƒåŠ é€Ÿ
pip install torch torchvision transformers scipy tqdm pillow -i https://pypi.tuna.tsinghua.edu.cn/simple
```

### æ­¥éª¤3: è¿è¡Œæµ‹è¯•

```bash
# æ–¹æ¡ˆA: ä½¿ç”¨æ ‡å‡†CLIPæµ‹è¯•ï¼ˆæ¨èå¼€å§‹ï¼‰
python3 test_correlation_demo.py

# æ–¹æ¡ˆB: å…ˆå¿«é€ŸæŸ¥çœ‹æ•°æ®ï¼ˆæ— éœ€ç­‰å¾…æ¨¡å‹ä¸‹è½½ï¼‰
python3 analyze_data.py
```

å°±è¿™ä¹ˆç®€å•ï¼ğŸ‰

---

## è¯¦ç»†è¯´æ˜

### âœ… æ–¹æ¡ˆA: ä½¿ç”¨æ ‡å‡†CLIPï¼ˆæ— éœ€EditCLIPæƒé‡ï¼‰

**ä¼˜ç‚¹**:
- âœ… æ— éœ€ä¸‹è½½é¢å¤–æ¨¡å‹æƒé‡
- âœ… ç«‹å³å¯ä»¥è¿è¡Œ
- âœ… å®Œæ•´å±•ç¤ºcorrelationæµ‹è¯•æµç¨‹

**è¿è¡Œ**:
```bash
python3 test_correlation_demo.py
```

**é¢„æœŸè¾“å‡º**:
```
============================================================
CLIP vs LLM Correlation Testing (Demo)
============================================================
Device: cuda (æˆ– cpu)
Data: magicbrush_data/data.json

Loading CLIP model (openai/clip-vit-large-patch14)...
âœ“ CLIP model loaded successfully
âœ“ Loaded 30 samples from MagicBrush

Evaluating with CLIP
============================================================
CLIP Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:15<00:00]

Generating Simulated LLM Scores
============================================================
âš ï¸  Using simulated LLM scores for demonstration

Computing Correlation Metrics
============================================================

Valid samples: 30 / 30

ğŸ“Š Correlation Results:
  Pearson  r =  0.xxxx  (p = x.xxxe-xx)
  Spearman Ï =  0.xxxx  (p = x.xxxe-xx)

ğŸ“ Error Metrics:
  MAE  = 0.xxxx
  RMSE = 0.xxxx

âœ… Results saved to correlation_results.json
```

**æŸ¥çœ‹ç»“æœ**:
```bash
# æŸ¥çœ‹correlationæŒ‡æ ‡
cat correlation_results.json | jq '.correlation_metrics'

# æŸ¥çœ‹å®Œæ•´ç»“æœ
cat correlation_results.json | jq '.'
```

### ğŸ”§ æ–¹æ¡ˆB: ä½¿ç”¨çœŸå®EditCLIPï¼ˆéœ€è¦ä¸‹è½½æƒé‡ï¼‰

å¦‚æœæ‚¨æƒ³ä½¿ç”¨çœŸå®çš„EditCLIPæ¨¡å‹ï¼š

**æ­¥éª¤1: ä¸‹è½½EditCLIPæƒé‡**

è®¿é—®: https://huggingface.co/QWW/EditCLIP

ä¸‹è½½ä»¥ä¸‹æ–‡ä»¶åˆ° `clip_ckpt/editclip_vit_l_14/`:
- `model.safetensors`
- `config.json`
- å…¶ä»–é…ç½®æ–‡ä»¶ï¼ˆå¦‚æœæœ‰ï¼‰

**æ­¥éª¤2: è¿è¡ŒEditCLIPç‰ˆæœ¬**
```bash
python3 test_correlation.py --model_path clip_ckpt/editclip_vit_l_14
```

---

## ğŸ“Š ç†è§£è¾“å‡ºç»“æœ

### correlation_results.json ç»“æ„

```json
{
  "metadata": {
    "n_samples": 30,
    "model_type": "CLIP (openai/clip-vit-large-patch14)",
    "llm_type": "simulated"
  },
  "correlation_metrics": {
    "n_samples": 30,
    "pearson_r": 0.xxxx,        // Pearsonç›¸å…³ç³»æ•°
    "pearson_p": 0.xxxx,        // ç»Ÿè®¡æ˜¾è‘—æ€§
    "spearman_r": 0.xxxx,       // Spearmanç›¸å…³ç³»æ•°
    "spearman_p": 0.xxxx,
    "mae": 0.xxxx,              // å¹³å‡ç»å¯¹è¯¯å·®
    "rmse": 0.xxxx              // å‡æ–¹æ ¹è¯¯å·®
  },
  "clip_results": [
    {
      "sample_id": 0,
      "instruction": "change the table for a dog",
      "edit_score": 0.xxxx,           // CLIPç¼–è¾‘è´¨é‡åˆ†æ•°
      "target_text_sim": 0.xxxx,      // ç¼–è¾‘åå›¾ç‰‡ä¸æŒ‡ä»¤çš„ç›¸ä¼¼åº¦
      "source_text_sim": 0.xxxx,      // åŸå›¾ä¸æŒ‡ä»¤çš„ç›¸ä¼¼åº¦
      "source_target_sim": 0.xxxx     // åŸå›¾ä¸ç¼–è¾‘åçš„ç›¸ä¼¼åº¦
    },
    ...
  ],
  "llm_results": [
    {
      "sample_id": 0,
      "llm_score": 0.xxxx,            // LLMè¯„ä¼°åˆ†æ•°
      "llm_model": "simulated"
    },
    ...
  ]
}
```

### å¦‚ä½•è§£è¯»ç›¸å…³ç³»æ•°

| Pearson r | å«ä¹‰ | è¯´æ˜ |
|-----------|------|------|
| 0.7 ~ 1.0 | å¼ºæ­£ç›¸å…³ | CLIPå’ŒLLMè¯„ä¼°é«˜åº¦ä¸€è‡´ |
| 0.4 ~ 0.7 | ä¸­ç­‰ç›¸å…³ | æœ‰ä¸€å®šä¸€è‡´æ€§ï¼Œä½†å­˜åœ¨å·®å¼‚ |
| 0.0 ~ 0.4 | å¼±ç›¸å…³ | è¯„ä¼°å·®å¼‚è¾ƒå¤§ |
| p < 0.05 | ç»Ÿè®¡æ˜¾è‘— | ç›¸å…³æ€§ä¸æ˜¯å¶ç„¶äº§ç”Ÿçš„ |

---

## ğŸ¨ å¯è§†åŒ–ç»“æœï¼ˆå¯é€‰ï¼‰

åˆ›å»ºæ•£ç‚¹å›¾æŸ¥çœ‹ç›¸å…³æ€§ï¼š

```bash
# åˆ›å»ºå¯è§†åŒ–è„šæœ¬
cat > visualize_results.py << 'EOF'
import json
import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import pearsonr

# è¯»å–ç»“æœ
with open('correlation_results.json') as f:
    data = json.load(f)

clip_scores = [r['edit_score'] for r in data['clip_results'] if r['edit_score'] is not None]
llm_scores = [r['llm_score'] for r in data['llm_results'] if r['llm_score'] is not None]

# åˆ›å»ºæ•£ç‚¹å›¾
plt.figure(figsize=(10, 6))
plt.scatter(clip_scores, llm_scores, alpha=0.6, s=100)

# æ·»åŠ è¶‹åŠ¿çº¿
z = np.polyfit(clip_scores, llm_scores, 1)
p = np.poly1d(z)
plt.plot(sorted(clip_scores), p(sorted(clip_scores)), "r--", alpha=0.8, label='Trend line')

# è®¡ç®—ç›¸å…³ç³»æ•°
r, p_val = pearsonr(clip_scores, llm_scores)

plt.xlabel('CLIP Edit Score', fontsize=12)
plt.ylabel('LLM Score', fontsize=12)
plt.title(f'CLIP vs LLM Evaluation Correlation\nPearson r = {r:.3f}, p = {p_val:.4f}', fontsize=14)
plt.grid(True, alpha=0.3)
plt.legend()
plt.tight_layout()
plt.savefig('correlation_plot.png', dpi=300)
print("âœ… Plot saved to correlation_plot.png")
plt.show()
EOF

# å®‰è£…matplotlibï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
pip install matplotlib

# è¿è¡Œå¯è§†åŒ–
python3 visualize_results.py
```

---

## ğŸ”„ ä¸‹ä¸€æ­¥ï¼šé›†æˆçœŸå®LLMè¯„ä¼°

å½“å‰ä½¿ç”¨æ¨¡æ‹ŸLLMåˆ†æ•°ã€‚è¦ä½¿ç”¨çœŸå®LLMï¼š

### æ–¹æ¡ˆ1: ä½¿ç”¨OpenAI GPT-4V

```python
# ä¿®æ”¹ test_correlation_demo.py ä¸­çš„ evaluate_with_llm å‡½æ•°

import openai
import base64

def evaluate_with_llm_gpt4v(samples, api_key):
    """ä½¿ç”¨GPT-4Vè¯„ä¼°"""
    openai.api_key = api_key
    results = []

    for sample in samples:
        # è¯»å–å›¾ç‰‡
        source_path = f"magicbrush_data/{sample['source_image']}"
        target_path = f"magicbrush_data/{sample['target_image']}"

        # Base64ç¼–ç 
        with open(source_path, 'rb') as f:
            source_b64 = base64.b64encode(f.read()).decode()
        with open(target_path, 'rb') as f:
            target_b64 = base64.b64encode(f.read()).decode()

        # è°ƒç”¨GPT-4V
        response = openai.ChatCompletion.create(
            model="gpt-4-vision-preview",
            messages=[{
                "role": "user",
                "content": [
                    {"type": "text", "text": f"Rate how well this edit follows the instruction: '{sample['instruction']}'. Source image:"},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{source_b64}"}},
                    {"type": "text", "text": "Edited image:"},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{target_b64}"}},
                    {"type": "text", "text": "Rate from 0 to 1 (0=poor, 1=perfect). Reply with only a number."}
                ]
            }],
            max_tokens=10
        )

        score = float(response.choices[0].message.content.strip())
        results.append({
            'sample_id': sample['id'],
            'llm_score': score,
            'llm_model': 'gpt-4-vision-preview'
        })

    return results
```

### æ–¹æ¡ˆ2: ä½¿ç”¨Anthropic Claude

```python
import anthropic
import base64

def evaluate_with_llm_claude(samples, api_key):
    """ä½¿ç”¨Claudeè¯„ä¼°"""
    client = anthropic.Anthropic(api_key=api_key)
    results = []

    for sample in samples:
        # è¯»å–å¹¶ç¼–ç å›¾ç‰‡
        source_path = f"magicbrush_data/{sample['source_image']}"
        target_path = f"magicbrush_data/{sample['target_image']}"

        with open(source_path, 'rb') as f:
            source_b64 = base64.b64encode(f.read()).decode()
        with open(target_path, 'rb') as f:
            target_b64 = base64.b64encode(f.read()).decode()

        # è°ƒç”¨Claude
        message = client.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=10,
            messages=[{
                "role": "user",
                "content": [
                    {"type": "text", "text": f"Rate how well this edit follows the instruction: '{sample['instruction']}'.\n\nSource image:"},
                    {"type": "image", "source": {"type": "base64", "media_type": "image/jpeg", "data": source_b64}},
                    {"type": "text", "text": "Edited image:"},
                    {"type": "image", "source": {"type": "base64", "media_type": "image/jpeg", "data": target_b64}},
                    {"type": "text", "text": "Rate from 0 to 1 (0=poor edit, 1=perfect edit). Reply with only a number."}
                ]
            }]
        )

        score = float(message.content[0].text.strip())
        results.append({
            'sample_id': sample['id'],
            'llm_score': score,
            'llm_model': 'claude-3-5-sonnet'
        })

    return results
```

ä½¿ç”¨çœŸå®LLMï¼š
```bash
# è®¾ç½®API key
export OPENAI_API_KEY="your-key-here"
# æˆ–
export ANTHROPIC_API_KEY="your-key-here"

# è¿è¡Œï¼ˆéœ€è¦ä¿®æ”¹è„šæœ¬ä½¿ç”¨ä¸Šè¿°å‡½æ•°ï¼‰
python3 test_correlation_demo.py --api_key $OPENAI_API_KEY
```

---

## ğŸ’¡ å¸¸è§é—®é¢˜

### Q: æ²¡æœ‰GPUæ€ä¹ˆåŠï¼Ÿ
A: è„šæœ¬ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨CPUã€‚é€Ÿåº¦ä¼šæ…¢ä¸€äº›ä½†å®Œå…¨å¯ç”¨ã€‚

### Q: å®‰è£…å¾ˆæ…¢ï¼Ÿ
A: ä½¿ç”¨å›½å†…é•œåƒï¼š
```bash
pip install torch torchvision -i https://pypi.tuna.tsinghua.edu.cn/simple
```

### Q: æƒ³è¦æ›´å¤šæ ·æœ¬ï¼Ÿ
A: è¿è¡Œ `download_magicbrush_50.py` ä¸‹è½½50ä¸ªæ ·æœ¬ï¼š
```bash
python3 download_magicbrush_50.py
```

### Q: å¦‚ä½•åªæµ‹è¯•ç‰¹å®šæ ·æœ¬ï¼Ÿ
A: ç¼–è¾‘ `magicbrush_data/data.json`ï¼Œåªä¿ç•™æ‚¨æƒ³æµ‹è¯•çš„æ ·æœ¬ã€‚

---

## âœ… æ£€æŸ¥æ¸…å•

å¼€å§‹å‰ç¡®è®¤ï¼š
- [ ] Gitå·²å®‰è£…
- [ ] Python 3.8+ å·²å®‰è£…
- [ ] å·²å…‹éš†EditCLIPä»“åº“
- [ ] å·²åˆ‡æ¢åˆ°æ­£ç¡®åˆ†æ”¯
- [ ] å·²å®‰è£…ä¾èµ–åŒ…
- [ ] magicbrush_data/ æ–‡ä»¶å¤¹å­˜åœ¨

è¿è¡Œæµ‹è¯•ï¼š
- [ ] è¿è¡Œ `python3 test_correlation_demo.py`
- [ ] æŸ¥çœ‹ correlation_results.json
- [ ] ç†è§£ç›¸å…³æ€§ç»“æœ

å¯é€‰è¿›é˜¶ï¼š
- [ ] å¯è§†åŒ–ç»“æœ
- [ ] é›†æˆçœŸå®LLM
- [ ] ä½¿ç”¨EditCLIPæƒé‡

---

ç¥æµ‹è¯•é¡ºåˆ©ï¼å¦‚æœé‡åˆ°é—®é¢˜ï¼Œå¯ä»¥æŸ¥çœ‹ `README_CORRELATION_TEST.md` è·å–æ›´å¤šå¸®åŠ©ã€‚ğŸ‰
