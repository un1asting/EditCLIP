# LLM-EditCLIP Correlation Testing

## ğŸ“Š æ•°æ®å‡†å¤‡å®Œæˆ

âœ… **MagicBrushæ•°æ®**: 30ä¸ªçœŸå®æ ·æœ¬
- æ•°æ®æ–‡ä»¶: `magicbrush_data/data.json`
- å›¾ç‰‡: `magicbrush_data/images/` (60å¼ å›¾ç‰‡ï¼Œ30å¯¹source/target)
- å¹³å‡æŒ‡ä»¤é•¿åº¦: 5.9è¯

## ğŸ”§ å¯ç”¨çš„æµ‹è¯•è„šæœ¬

### 1. **test_correlation_demo.py** (æ¨è)
å®Œæ•´çš„correlationæµ‹è¯•è„šæœ¬ï¼Œä½¿ç”¨æ ‡å‡†CLIPæ¨¡å‹

**åŠŸèƒ½**:
- åŠ è½½CLIPæ¨¡å‹è¯„ä¼°æ‰€æœ‰æ ·æœ¬
- ç”ŸæˆLLMè¯„ä¼°åˆ†æ•°ï¼ˆå¯æ¨¡æ‹Ÿæˆ–çœŸå®APIï¼‰
- è®¡ç®—Pearsonå’ŒSpearmanç›¸å…³ç³»æ•°
- ç”Ÿæˆè¯¦ç»†åˆ†ææŠ¥å‘Š

**è¿è¡Œ**:
```bash
# éœ€è¦å…ˆå®‰è£…ä¾èµ–
pip install torch torchvision transformers scipy tqdm

# è¿è¡Œæµ‹è¯•
python3 test_correlation_demo.py

# æŒ‡å®šè¾“å‡ºæ–‡ä»¶
python3 test_correlation_demo.py --output my_results.json
```

**è¾“å‡º**: `correlation_results.json` åŒ…å«:
- Pearsonç›¸å…³ç³»æ•°
- Spearmanç›¸å…³ç³»æ•°
- MAE, RMSEç­‰è¯¯å·®æŒ‡æ ‡
- æ¯ä¸ªæ ·æœ¬çš„è¯¦ç»†åˆ†æ•°
- Top/Bottomæ ·æœ¬åˆ†æ

### 2. **test_correlation.py**
ä½¿ç”¨EditCLIPæ¨¡å‹çš„å®Œæ•´ç‰ˆæœ¬ï¼ˆéœ€è¦ä¸‹è½½æ¨¡å‹æƒé‡ï¼‰

**ä½¿ç”¨å‰éœ€è¦**:
```bash
# ä¸‹è½½EditCLIPæ¨¡å‹æƒé‡
# ä» https://huggingface.co/QWW/EditCLIP
# è§£å‹åˆ° clip_ckpt/editclip_vit_l_14/
```

### 3. **analyze_data.py**
å¿«é€Ÿæ•°æ®åˆ†æè„šæœ¬ï¼ˆæ— éœ€PyTorchï¼‰

```bash
python3 analyze_data.py
```

## ğŸ“ˆ è¯„ä¼°æ–¹æ³•

### CLIP/EditCLIPè¯„ä¼°
è®¡ç®—ç¼–è¾‘è´¨é‡åˆ†æ•°ï¼š
```
edit_score = similarity(target_image, instruction) - similarity(source_image, instruction)
```

- æ­£åˆ†æ•°ï¼šç¼–è¾‘æ”¹å–„äº†ä¸æŒ‡ä»¤çš„å¯¹é½
- è´Ÿåˆ†æ•°ï¼šç¼–è¾‘ä½¿å›¾åƒåç¦»äº†æŒ‡ä»¤
- åˆ†æ•°è¶Šé«˜ï¼Œç¼–è¾‘è´¨é‡è¶Šå¥½

### LLMè¯„ä¼°
å¯ä»¥ä½¿ç”¨GPT-4 Visionæˆ–Claudeè¯„ä¼°ç¼–è¾‘è´¨é‡ï¼š
1. å±•ç¤ºsourceå’Œtargetå›¾ç‰‡
2. æä¾›editingæŒ‡ä»¤
3. è®©LLMæ‰“åˆ†(0-1æˆ–1-10)

**å½“å‰çŠ¶æ€**: è„šæœ¬åŒ…å«æ¨¡æ‹ŸLLMè¯„ä¼°ã€‚è¦ä½¿ç”¨çœŸå®APIï¼Œéœ€è¦ï¼š
- è®¾ç½®API key
- å®ç°APIè°ƒç”¨é€»è¾‘ï¼ˆå·²æœ‰æ¨¡æ¿ï¼‰

## ğŸ“Š ç›¸å…³æ€§æŒ‡æ ‡

è„šæœ¬ä¼šè®¡ç®—ï¼š

| æŒ‡æ ‡ | è¯´æ˜ | ç†æƒ³å€¼ |
|-----|------|--------|
| **Pearson r** | çº¿æ€§ç›¸å…³ | æ¥è¿‘Â±1 |
| **Spearman Ï** | å•è°ƒç›¸å…³ | æ¥è¿‘Â±1 |
| **p-value** | æ˜¾è‘—æ€§ | <0.05 |
| **MAE** | å¹³å‡ç»å¯¹è¯¯å·® | è¶Šå°è¶Šå¥½ |
| **RMSE** | å‡æ–¹æ ¹è¯¯å·® | è¶Šå°è¶Šå¥½ |

### ç›¸å…³ç³»æ•°è§£é‡Š
- **|r| > 0.7**: å¼ºç›¸å…³
- **0.4 < |r| < 0.7**: ä¸­ç­‰ç›¸å…³
- **|r| < 0.4**: å¼±ç›¸å…³
- **p < 0.05**: ç»Ÿè®¡æ˜¾è‘—

## ğŸš€ å¿«é€Ÿå¼€å§‹

```bash
# 1. å®‰è£…ä¾èµ–ï¼ˆå¦‚æœè¿˜æ²¡å®‰è£…ï¼‰
pip install torch torchvision transformers scipy tqdm

# 2. è¿è¡Œcorrelationæµ‹è¯•
python3 test_correlation_demo.py

# 3. æŸ¥çœ‹ç»“æœ
cat correlation_results.json | jq '.correlation_metrics'
```

## ğŸ“ é¢„æœŸè¾“å‡ºç¤ºä¾‹

```
============================================================
CLIP vs LLM Correlation Testing (Demo)
============================================================
Device: cuda
Data: magicbrush_data/data.json

âœ“ Loaded 30 samples from MagicBrush
âœ“ CLIP model loaded successfully

Evaluating with CLIP
============================================================
[è¿›åº¦æ¡æ˜¾ç¤ºå¤„ç†æ¯ä¸ªæ ·æœ¬...]

Generating Simulated LLM Scores
============================================================
âš ï¸  Using simulated LLM scores for demonstration

Computing Correlation Metrics
============================================================

Valid samples: 30 / 30

ğŸ“Š Correlation Results:
  Pearson  r =  0.xxxx  (p = x.xxxe-xx)
  Spearman Ï =  0.xxxx  (p = x.xxxe-xx)

ğŸ“ Error Metrics (normalized scores):
  MAE  = 0.xxxx
  RMSE = 0.xxxx

ğŸ“ˆ Score Statistics:
  CLIP:  mean=0.xxxx, std=0.xxxx, range=[xxx, xxx]
  LLM:   mean=0.xxxx, std=0.xxxx, range=[xxx, xxx]

ğŸ’¡ Interpretation:
  [è‡ªåŠ¨è§£é‡Šç›¸å…³æ€§å¼ºåº¦å’Œæ˜¾è‘—æ€§]

âœ… Top 3 samples with best agreement
  [æ˜¾ç¤ºæœ€ä¸€è‡´çš„æ ·æœ¬]

âŒ Bottom 3 samples with worst agreement
  [æ˜¾ç¤ºæœ€ä¸ä¸€è‡´çš„æ ·æœ¬]

âœ… Results saved to correlation_results.json
```

## ğŸ“¦ è¾“å‡ºæ–‡ä»¶ç»“æ„

`correlation_results.json`:
```json
{
  "metadata": {
    "n_samples": 30,
    "model_type": "CLIP (openai/clip-vit-large-patch14)",
    "llm_type": "simulated",
    "device": "cuda"
  },
  "correlation_metrics": {
    "n_samples": 30,
    "pearson_r": 0.xxxx,
    "pearson_p": 0.xxxx,
    "spearman_r": 0.xxxx,
    "spearman_p": 0.xxxx,
    "mae": 0.xxxx,
    "rmse": 0.xxxx
  },
  "clip_results": [...],
  "llm_results": [...]
}
```

## ğŸ”„ ä¸‹ä¸€æ­¥

1. **å½“å‰**: ä½¿ç”¨CLIP + æ¨¡æ‹ŸLLMæµ‹è¯•æµç¨‹
2. **æ”¹è¿›1**: ä½¿ç”¨EditCLIPæ¨¡å‹ï¼ˆä¸‹è½½æƒé‡ï¼‰
3. **æ”¹è¿›2**: é›†æˆçœŸå®LLM APIï¼ˆGPT-4V/Claudeï¼‰
4. **åˆ†æ**: æŒ‰ç¼–è¾‘ç±»å‹åˆ†æç›¸å…³æ€§å·®å¼‚

## âš ï¸ æ³¨æ„äº‹é¡¹

- CLIPæ¨¡å‹é¦–æ¬¡åŠ è½½ä¼šä¸‹è½½çº¦1.7GB
- GPUæ¨èä½†éå¿…éœ€ï¼ˆCPUä¹Ÿå¯è¿è¡Œï¼‰
- æ¨¡æ‹ŸLLMåˆ†æ•°ä»…ç”¨äºæ¼”ç¤ºæµç¨‹
- çœŸå®è¯„ä¼°éœ€è¦LLM API access

## ğŸ“š ç›¸å…³èµ„æº

- **EditCLIPè®ºæ–‡**: https://arxiv.org/abs/2503.20318
- **EditCLIPæƒé‡**: https://huggingface.co/QWW/EditCLIP
- **MagicBrushæ•°æ®é›†**: https://huggingface.co/datasets/osunlp/MagicBrush
